{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\anaconda3\\envs\\ANZ\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'TF',\n",
       " 'Bigram TF',\n",
       " 'No. of Stop_words',\n",
       " 'Out of Context',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Conspiracy',\n",
       " 'Business and Industrial',\n",
       " 'economy, business and finance',\n",
       " 'Religion and belief',\n",
       " 'Law, Government and Politics',\n",
       " 'Education',\n",
       " 'Technology and Computing',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'ORG',\n",
       " 'PERSON',\n",
       " 'GPE']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('kaggle-ner.csv')\n",
    "list(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emergent_page',\n",
       " 'claim',\n",
       " 'claim_description',\n",
       " 'claim_label',\n",
       " 'tags',\n",
       " 'claim_source_domain',\n",
       " 'claim_course_url',\n",
       " 'date',\n",
       " 'body',\n",
       " 'page_domain',\n",
       " 'page_url',\n",
       " 'page_headline',\n",
       " 'page_position',\n",
       " 'page_shares',\n",
       " 'page_order',\n",
       " 'claim_pos',\n",
       " 'spelling',\n",
       " 'grammar_error',\n",
       " 'topic modelling',\n",
       " 'clean_text',\n",
       " 'TF',\n",
       " 'out of context terms',\n",
       " 'out of context final',\n",
       " 'Textrazor_category',\n",
       " 'Textrazor_topic',\n",
       " 'Topics_category',\n",
       " 'Topics_topic',\n",
       " 'score_category',\n",
       " 'score_topic',\n",
       " 'category_score_final',\n",
       " 'category_list_final',\n",
       " 'topic_score_final',\n",
       " 'topic_list_final',\n",
       " 'TF_temp',\n",
       " 'formula 1',\n",
       " 'formula 2',\n",
       " 'bigram TF',\n",
       " 'bigram TF final',\n",
       " 'No. of stop_words',\n",
       " 'arts, culture and entertainment',\n",
       " 'Conspiracy',\n",
       " 'crime, law and justice',\n",
       " 'Criticism of journalism',\n",
       " 'Advertising video on demand',\n",
       " 'computing and information technology',\n",
       " 'agriculture',\n",
       " 'energy and resource',\n",
       " 'economy, business and finance',\n",
       " 'Harassment',\n",
       " 'Cyberspace',\n",
       " 'religion and belief',\n",
       " 'Politics and technology',\n",
       " 'Social media',\n",
       " 'science and technology',\n",
       " 'Social epistemology',\n",
       " 'social issue',\n",
       " 'environmental issue',\n",
       " 'Academia',\n",
       " 'Attacks',\n",
       " 'Feminism',\n",
       " 'Sports',\n",
       " 'Internet-Cyberspace',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Business and Industrial',\n",
       " 'Law, Government and Politics',\n",
       " 'religion & social epistemology']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_pickle('KaggleEmergent-dup.pkl')\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 27 columns):\n",
      "TF                                      107 non-null float64\n",
      "Bigram TF                               107 non-null int64\n",
      "No. of Stop_words                       107 non-null float64\n",
      "Out of Context                          107 non-null float64\n",
      "Arts, Culture, Entertainment, Sports    107 non-null float64\n",
      "Conspiracy                              107 non-null float64\n",
      "Business and Industrial                 107 non-null float64\n",
      "economy, business and finance           107 non-null float64\n",
      "Religion and belief                     107 non-null float64\n",
      "Law, Government and Politics            107 non-null float64\n",
      "Education                               107 non-null float64\n",
      "Technology and Computing                107 non-null float64\n",
      "Science                                 107 non-null float64\n",
      "Sixltr                                  107 non-null float64\n",
      "conj                                    107 non-null float64\n",
      "interrog                                107 non-null float64\n",
      "number                                  107 non-null float64\n",
      "negemo                                  107 non-null float64\n",
      "social                                  107 non-null float64\n",
      "certain                                 107 non-null float64\n",
      "percept                                 107 non-null float64\n",
      "focuspast                               107 non-null float64\n",
      "focuspresent                            107 non-null float64\n",
      "time                                    107 non-null float64\n",
      "ORG                                     107 non-null float64\n",
      "PERSON                                  107 non-null float64\n",
      "GPE                                     107 non-null float64\n",
      "dtypes: float64(26), int64(1)\n",
      "memory usage: 22.7 KB\n"
     ]
    }
   ],
   "source": [
    "features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "features.fillna(0,inplace=True)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=features.loc[:,['TF','Bigram TF','No. of Stop_words', 'Out of Context', 'Religion and belief', 'Law, Government and Politics',\n",
    " 'Sixltr', 'conj', 'interrog', 'number', 'negemo', 'social', 'certain', 'percept', 'focuspast', 'focuspresent', 'time',\n",
    " 'PERSON', 'ORG','GPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dependant variable y\n",
    "y= df.loc[:,['claim_label']]\n",
    "#mapping the labels to respective numeric terms\n",
    "dict = {'FALSE' : 0, 'TRUE' : 1, 'Unverified' : 2}\n",
    "y=y.replace({\"claim_label\": dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claim_label\n",
       "0               2\n",
       "3               2\n",
       "12              2\n",
       "24              0\n",
       "34              0\n",
       "...           ...\n",
       "1715            2\n",
       "1732            2\n",
       "2130            2\n",
       "2134            2\n",
       "2138            2\n",
       "\n",
       "[107 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.iloc[:,0].values\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 20\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = input_dim ,kernel_initializer='he_uniform', bias_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform', bias_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='he_uniform', bias_initializer='zeros', activation = 'relu'))\n",
    "# model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1.4957 - accuracy: 0.4471\n",
      "Epoch 2/45\n",
      "85/85 [==============================] - 0s 273us/step - loss: 1.2069 - accuracy: 0.4118\n",
      "Epoch 3/45\n",
      "85/85 [==============================] - 0s 259us/step - loss: 1.1169 - accuracy: 0.4471\n",
      "Epoch 4/45\n",
      "85/85 [==============================] - 0s 269us/step - loss: 1.0647 - accuracy: 0.4706\n",
      "Epoch 5/45\n",
      "85/85 [==============================] - 0s 277us/step - loss: 1.0303 - accuracy: 0.4471\n",
      "Epoch 6/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 1.0009 - accuracy: 0.4824\n",
      "Epoch 7/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.9733 - accuracy: 0.5059\n",
      "Epoch 8/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.9514 - accuracy: 0.5647\n",
      "Epoch 9/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.9279 - accuracy: 0.5647\n",
      "Epoch 10/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.9073 - accuracy: 0.5882\n",
      "Epoch 11/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.8886 - accuracy: 0.6118\n",
      "Epoch 12/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.8714 - accuracy: 0.6235\n",
      "Epoch 13/45\n",
      "85/85 [==============================] - 0s 274us/step - loss: 0.8542 - accuracy: 0.6588\n",
      "Epoch 14/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.8362 - accuracy: 0.6588\n",
      "Epoch 15/45\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.8195 - accuracy: 0.6706\n",
      "Epoch 16/45\n",
      "85/85 [==============================] - 0s 281us/step - loss: 0.8026 - accuracy: 0.6588\n",
      "Epoch 17/45\n",
      "85/85 [==============================] - 0s 234us/step - loss: 0.7873 - accuracy: 0.6471\n",
      "Epoch 18/45\n",
      "85/85 [==============================] - 0s 269us/step - loss: 0.7754 - accuracy: 0.6824\n",
      "Epoch 19/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.7580 - accuracy: 0.6706\n",
      "Epoch 20/45\n",
      "85/85 [==============================] - 0s 257us/step - loss: 0.7471 - accuracy: 0.6824\n",
      "Epoch 21/45\n",
      "85/85 [==============================] - 0s 281us/step - loss: 0.7332 - accuracy: 0.6824\n",
      "Epoch 22/45\n",
      "85/85 [==============================] - 0s 291us/step - loss: 0.7193 - accuracy: 0.7059\n",
      "Epoch 23/45\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.7048 - accuracy: 0.7176\n",
      "Epoch 24/45\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.6941 - accuracy: 0.7059\n",
      "Epoch 25/45\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.6834 - accuracy: 0.7294\n",
      "Epoch 26/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.6707 - accuracy: 0.7176\n",
      "Epoch 27/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.6589 - accuracy: 0.7529\n",
      "Epoch 28/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.6468 - accuracy: 0.7647\n",
      "Epoch 29/45\n",
      "85/85 [==============================] - 0s 291us/step - loss: 0.6373 - accuracy: 0.7529\n",
      "Epoch 30/45\n",
      "85/85 [==============================] - 0s 281us/step - loss: 0.6247 - accuracy: 0.7765\n",
      "Epoch 31/45\n",
      "85/85 [==============================] - 0s 293us/step - loss: 0.6148 - accuracy: 0.7765\n",
      "Epoch 32/45\n",
      "85/85 [==============================] - 0s 282us/step - loss: 0.6031 - accuracy: 0.8000\n",
      "Epoch 33/45\n",
      "85/85 [==============================] - 0s 246us/step - loss: 0.5910 - accuracy: 0.8000\n",
      "Epoch 34/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.5801 - accuracy: 0.7882\n",
      "Epoch 35/45\n",
      "85/85 [==============================] - 0s 246us/step - loss: 0.5690 - accuracy: 0.8118\n",
      "Epoch 36/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.5588 - accuracy: 0.8118\n",
      "Epoch 37/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.5481 - accuracy: 0.8118\n",
      "Epoch 38/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.5388 - accuracy: 0.8118\n",
      "Epoch 39/45\n",
      "85/85 [==============================] - 0s 246us/step - loss: 0.5294 - accuracy: 0.8118\n",
      "Epoch 40/45\n",
      "85/85 [==============================] - 0s 270us/step - loss: 0.5198 - accuracy: 0.8353\n",
      "Epoch 41/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.5125 - accuracy: 0.8353\n",
      "Epoch 42/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.5021 - accuracy: 0.8353\n",
      "Epoch 43/45\n",
      "85/85 [==============================] - 0s 258us/step - loss: 0.4922 - accuracy: 0.8471\n",
      "Epoch 44/45\n",
      "85/85 [==============================] - 0s 257us/step - loss: 0.4842 - accuracy: 0.8353\n",
      "Epoch 45/45\n",
      "85/85 [==============================] - 0s 293us/step - loss: 0.4727 - accuracy: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dc26a7f128>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs = 45, batch_size = 4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "\n",
      "accuracy: 54.55%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[6 2 1]\n",
      " [3 2 2]\n",
      " [1 1 4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(np.argmax(test_y, axis=-1), y_pred)\n",
    "\n",
    "print(\"Confusion matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANZ",
   "language": "python",
   "name": "anz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
