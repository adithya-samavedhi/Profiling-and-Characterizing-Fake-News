{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'TF',\n",
       " 'Bigram TF',\n",
       " 'No. of Stop_words',\n",
       " 'Out of Context',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Conspiracy',\n",
       " 'Business and Industrial',\n",
       " 'economy, business and finance',\n",
       " 'Religion and belief',\n",
       " 'Law, Government and Politics',\n",
       " 'Education',\n",
       " 'Technology and Computing',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'ORG',\n",
       " 'PERSON',\n",
       " 'GPE']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('kaggle-ner.csv')\n",
    "list(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 27 columns):\n",
      "TF                                      107 non-null float64\n",
      "Bigram TF                               107 non-null int64\n",
      "No. of Stop_words                       107 non-null float64\n",
      "Out of Context                          107 non-null float64\n",
      "Arts, Culture, Entertainment, Sports    107 non-null float64\n",
      "Conspiracy                              107 non-null float64\n",
      "Business and Industrial                 107 non-null float64\n",
      "economy, business and finance           107 non-null float64\n",
      "Religion and belief                     107 non-null float64\n",
      "Law, Government and Politics            107 non-null float64\n",
      "Education                               107 non-null float64\n",
      "Technology and Computing                107 non-null float64\n",
      "Science                                 107 non-null float64\n",
      "Sixltr                                  107 non-null float64\n",
      "conj                                    107 non-null float64\n",
      "interrog                                107 non-null float64\n",
      "number                                  107 non-null float64\n",
      "negemo                                  107 non-null float64\n",
      "social                                  107 non-null float64\n",
      "certain                                 107 non-null float64\n",
      "percept                                 107 non-null float64\n",
      "focuspast                               107 non-null float64\n",
      "focuspresent                            107 non-null float64\n",
      "time                                    107 non-null float64\n",
      "ORG                                     107 non-null float64\n",
      "PERSON                                  107 non-null float64\n",
      "GPE                                     107 non-null float64\n",
      "dtypes: float64(26), int64(1)\n",
      "memory usage: 22.7 KB\n"
     ]
    }
   ],
   "source": [
    "features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "features.fillna(0,inplace=True)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emergent_page',\n",
       " 'claim',\n",
       " 'claim_description',\n",
       " 'claim_label',\n",
       " 'tags',\n",
       " 'claim_source_domain',\n",
       " 'claim_course_url',\n",
       " 'date',\n",
       " 'body',\n",
       " 'page_domain',\n",
       " 'page_url',\n",
       " 'page_headline',\n",
       " 'page_position',\n",
       " 'page_shares',\n",
       " 'page_order',\n",
       " 'claim_pos',\n",
       " 'spelling',\n",
       " 'grammar_error',\n",
       " 'topic modelling',\n",
       " 'clean_text',\n",
       " 'TF',\n",
       " 'out of context terms',\n",
       " 'out of context final',\n",
       " 'Textrazor_category',\n",
       " 'Textrazor_topic',\n",
       " 'Topics_category',\n",
       " 'Topics_topic',\n",
       " 'score_category',\n",
       " 'score_topic',\n",
       " 'category_score_final',\n",
       " 'category_list_final',\n",
       " 'topic_score_final',\n",
       " 'topic_list_final',\n",
       " 'TF_temp',\n",
       " 'formula 1',\n",
       " 'formula 2',\n",
       " 'bigram TF',\n",
       " 'bigram TF final',\n",
       " 'No. of stop_words',\n",
       " 'arts, culture and entertainment',\n",
       " 'Conspiracy',\n",
       " 'crime, law and justice',\n",
       " 'Criticism of journalism',\n",
       " 'Advertising video on demand',\n",
       " 'computing and information technology',\n",
       " 'agriculture',\n",
       " 'energy and resource',\n",
       " 'economy, business and finance',\n",
       " 'Harassment',\n",
       " 'Cyberspace',\n",
       " 'religion and belief',\n",
       " 'Politics and technology',\n",
       " 'Social media',\n",
       " 'science and technology',\n",
       " 'Social epistemology',\n",
       " 'social issue',\n",
       " 'environmental issue',\n",
       " 'Academia',\n",
       " 'Attacks',\n",
       " 'Feminism',\n",
       " 'Sports',\n",
       " 'Internet-Cyberspace',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Business and Industrial',\n",
       " 'Law, Government and Politics',\n",
       " 'religion & social epistemology']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_pickle('KaggleEmergent-dup.pkl')\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=features.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dependant variable y\n",
    "y= df.loc[:,['claim_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>Unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    claim_label\n",
       "3    Unverified\n",
       "12   Unverified\n",
       "24        FALSE\n",
       "34        FALSE\n",
       "41         TRUE\n",
       "52        FALSE\n",
       "56        FALSE\n",
       "63        FALSE\n",
       "66   Unverified\n",
       "78   Unverified\n",
       "86        FALSE\n",
       "102       FALSE\n",
       "113  Unverified\n",
       "119       FALSE\n",
       "135  Unverified\n",
       "140        TRUE\n",
       "146  Unverified\n",
       "156       FALSE\n",
       "164  Unverified\n",
       "177        TRUE\n",
       "182        TRUE\n",
       "192        TRUE\n",
       "213  Unverified\n",
       "224  Unverified\n",
       "241       FALSE\n",
       "248  Unverified\n",
       "263        TRUE\n",
       "274        TRUE\n",
       "286        TRUE\n",
       "304       FALSE\n",
       "312  Unverified\n",
       "322  Unverified\n",
       "335       FALSE\n",
       "354       FALSE\n",
       "382  Unverified\n",
       "465  Unverified\n",
       "607  Unverified\n",
       "615  Unverified\n",
       "623  Unverified\n",
       "647  Unverified\n",
       "662  Unverified\n",
       "671  Unverified\n",
       "675       FALSE\n",
       "688  Unverified\n",
       "697       FALSE\n",
       "700        TRUE\n",
       "704       FALSE\n",
       "708  Unverified\n",
       "722       FALSE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the labels to respective numeric terms\n",
    "dict = {'FALSE' : 0, 'TRUE' : 1, 'Unverified' : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.replace({\"Label\": dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #splitting our data into train and test, 20% test and 80% train\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 99  49  64  36  59  52  33  61 103  67  79  72  54 106  84  77  24  48\n",
      "  82  68 102   2  60   4  30  38   1  98  65  40  22  44  14  37  80  41\n",
      "  86  28  93  42 105  71  45  34   6  51  10  32  95  88  89  94  47  83\n",
      "  92  57  97  91  11  15  76  85  70  16 101  81  20  18  27  13  29  23\n",
      "  74  17  50  87  46  73  66  19  43   9  75   8  78] TEST: [ 25  31  56  63  21  26  62  58  53   0 104  12  69  39  90 100   3  55\n",
      "  35   7   5  96]\n",
      "TRAIN: [ 94 100  43  20  99  42  83  40  59  64  67  23  97  31  21   0  76  19\n",
      "  24  56 104  50  63  53  61  49  69  60  13  14  75  18   3   7  93  66\n",
      "  88  15  89  79  47  45  48  52  32  54  65  85  37 102   4  92  36 101\n",
      "  44  28  70   8  98  25  58  74  81  90  17  86  87   9 106  41  34  26\n",
      "  77  29  10  95  55  51   2  84  78  68   1  12  35] TEST: [ 46  72  73  82  11  22 105  30 103  33  38  91   5  80  62   6  27  96\n",
      "  57  16  71  39]\n",
      "TRAIN: [ 43   2  36  24 101  59  45   5  70  65  72 102  33  93  12  28  34  39\n",
      "  77  60   9  95 103  75  98   1  27  67  18  37  15  91  31  61  44  68\n",
      "  85  54  78  76  49   8  19  47  55  81  52  63  38  58  74  92  84  90\n",
      "  96  53  99   6  26  51  42  14 104 100  62  73  11  29  32  10  83  64\n",
      "  80  30 105  48  88  79  71  66  41  97  35  89  94] TEST: [ 20  46  86  57  50   4  13  87  23   3  21   7  69  25 106  16  82  56\n",
      "  40  22   0  17]\n",
      "TRAIN: [106  20  29   3  69  15  99  13  44  58  79   6   4  28  46  53  88  38\n",
      "  85  19  93  96  14  81  80  75  91  18  59  33  49  35  42  98  77 100\n",
      "  84 105  83  16  21  89 104  87  26  47  30  63 103  25  97  86  17  34\n",
      "  40  36  82  24 102 101  76  43  71  62  64  56  57  51  10  94  61  22\n",
      "  55  95   0  39  73  31  12  68  32  27  78   9  74] TEST: [52 11  8  2  1  5  7 60 45 23 67 92 54 41 65 70 50 48 72 66 90 37]\n",
      "TRAIN: [ 68  54  39   6   3  30  31  62  38  55  23   0  79  89 105  53  88  35\n",
      "  44  94  24  95  61  56  66  70 102  86  43  46  59   2  63   7  42  97\n",
      "  15  72  83  99  93  60  74  64  90  32  10  40  26  17  87  84   5  41\n",
      "  52  77  33  29  21  80  73  50  92  58  11   4  19 100  96  18  57  78\n",
      "  20  67  69  13  75 104   9  36  65  34  85 101  12] TEST: [ 91  28  47 106  27  48  45  82   8  49 103  51  71  14  37  76  16   1\n",
      "  25  98  81  22]\n"
     ]
    }
   ],
   "source": [
    "#Stratified split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit( n_splits=5, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying feature scaling so that training is faster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Applying LDA\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# lda = LDA(n_components = 5)\n",
    "# X_train = lda.fit_transform(X_train, y_train)\n",
    "# X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with Naive Bayes: \n",
      "[[2 1 5]\n",
      " [0 1 4]\n",
      " [0 0 9]]\n",
      "Accuracy with Naive Bayes: \n",
      "0.5454545454545454\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.5402777777777777\n",
      "0.08412815400504338\n"
     ]
    }
   ],
   "source": [
    "#classifier naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix with Naive Bayes: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with Naive Bayes: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n",
    "# from sklearn import  metrics\n",
    "# roc_curve = metrics.plot_roc_curve(classifier, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with random forests: \n",
      "[[4 0 4]\n",
      " [2 2 1]\n",
      " [4 0 5]]\n",
      "Accuracy with random forests: \n",
      "0.5\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.611111111111111\n",
      "0.1259225217404793\n",
      "Accuracy with Grid search :\n",
      "0.611111111111111\n",
      "Best parameters for random forests for best accuracy\n",
      "{'criterion': 'entropy', 'max_features': None, 'n_estimators': 5, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 42, max_features=None)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix with random forests: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with random forests: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n",
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [4,5,6,7,8,10,11,12], 'criterion': ['entropy', 'gini'], 'random_state':[42], 'max_features':['auto', \"sqrt\", 'log2', None ]}\n",
    "             ]\n",
    "    \n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Accuracy with Grid search :\")\n",
    "print(best_accuracy)\n",
    "\n",
    "print(\"Best parameters for random forests for best accuracy\")\n",
    "print(best_parameters)\n",
    "\n",
    "# from sklearn import  metrics\n",
    "# roc_curve = metrics.plot_roc_curve(classifier, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with decision tree: \n",
      "[[3 3 2]\n",
      " [1 3 1]\n",
      " [1 3 5]]\n",
      "Accuracy with decision tree: \n",
      "0.5\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.5291666666666666\n",
      "0.1821987196903154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix with decision tree: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with decision tree: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.08659356, 0.11802888, 0.0267215 ,\n",
       "       0.        , 0.        , 0.        , 0.03072125, 0.        ,\n",
       "       0.        , 0.05948605, 0.03382599, 0.        , 0.09085101,\n",
       "       0.05142893, 0.13046006, 0.12180437, 0.15750178, 0.0622494 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.03032723])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with K Nearest Neighbours: \n",
      "[[4 0 4]\n",
      " [2 2 1]\n",
      " [1 1 7]]\n",
      "Accuracy with K nearest Neighbours: \n",
      "0.5909090909090909\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.575\n",
      "0.13525809804377611\n",
      "Accuracy with Grid search :\n",
      "0.575\n",
      "Best parameters for KNN for best accuracy\n",
      "{'algorithm': 'auto', 'n_neighbors': 6, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 6, p = 1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix with K Nearest Neighbours: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with K nearest Neighbours: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n",
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_neighbors': [4,3,5,6,7,8], 'p':[1, 2], \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute'] }]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Accuracy with Grid search :\")\n",
    "print(best_accuracy)\n",
    "\n",
    "print(\"Best parameters for KNN for best accuracy\")\n",
    "print(best_parameters)\n",
    "# from sklearn import  metrics\n",
    "# roc_curve = metrics.plot_roc_curve(classifier, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with XGBoost: \n",
      "[[4 0 4]\n",
      " [0 3 2]\n",
      " [2 2 5]]\n",
      "Accuracy with XGBoost: \n",
      "0.5454545454545454\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.5513888888888889\n",
      "0.13566394801170817\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix with XGBoost: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with XGBoost: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n",
    "# from sklearn import  metrics\n",
    "# roc_curve = metrics.plot_roc_curve(classifier, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with kernel SVM: \n",
      "[[1 1 6]\n",
      " [0 3 2]\n",
      " [2 0 7]]\n",
      "Accuracy with kernel SVM: \n",
      "0.5\n",
      "Accuracy and Standard deviation after applying k-fold cross validation, k=10\n",
      "0.6333333333333334\n",
      "0.11354963019983164\n",
      "Accuracy with Grid search :\n",
      "0.6333333333333334\n",
      "Best parameters for SVM for best accuracy\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0, gamma='scale')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix with kernel SVM: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with kernel SVM: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy and Standard deviation after applying k-fold cross validation, k=10\")\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())\n",
    "\n",
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [ {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': ['scale','auto']}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Accuracy with Grid search :\")\n",
    "print(best_accuracy)\n",
    "\n",
    "print(\"Best parameters for SVM for best accuracy\")\n",
    "print(best_parameters)\n",
    "\n",
    "# roc_curve = plot_roc_curve(classifier, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
