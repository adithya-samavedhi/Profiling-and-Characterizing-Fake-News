{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\anaconda3\\envs\\ANZ\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('FakeNewsMaster-FS-nodup.csv')\n",
    "features.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TF',\n",
       " 'Bigram TF',\n",
       " 'No. of Stop_words',\n",
       " 'Out of Context',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Conspiracy',\n",
       " 'Business and Industrial',\n",
       " 'economy, business and finance',\n",
       " 'Religion and belief',\n",
       " 'Law, Government and Politics',\n",
       " 'Education',\n",
       " 'Technology and Computing',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'PERSON',\n",
       " 'TIME',\n",
       " 'ORG',\n",
       " 'GPE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'url',\n",
       " 'title',\n",
       " 'tweet_id',\n",
       " 'text',\n",
       " 'date',\n",
       " 'grammatical errors',\n",
       " 'Label',\n",
       " 'Clean_text',\n",
       " 'TF_temp',\n",
       " 'TF',\n",
       " 'Bigram TF_temp',\n",
       " 'Bigram TF',\n",
       " 'No. of Stop_words',\n",
       " 'Out of Context temp',\n",
       " 'Out of Context',\n",
       " 'Textrazor_category',\n",
       " 'Textrazor_topic',\n",
       " 'Topics_category',\n",
       " 'Topics_topic',\n",
       " 'score_category',\n",
       " 'score_topic',\n",
       " 'category_score_final',\n",
       " 'category_list_final',\n",
       " 'topic_score_final',\n",
       " 'topic_list_final',\n",
       " 'arts, culture and entertainment',\n",
       " 'Conspiracy',\n",
       " 'crime, law and justice',\n",
       " 'Criticism of journalism',\n",
       " 'Advertising video on demand',\n",
       " 'computing and information technology',\n",
       " 'agriculture',\n",
       " 'energy and resource',\n",
       " 'economy, business and finance',\n",
       " 'Harassment',\n",
       " 'Cyberspace',\n",
       " 'religion and belief',\n",
       " 'Politics and technology',\n",
       " 'Social media',\n",
       " 'science and technology',\n",
       " 'Social epistemology',\n",
       " 'social issue',\n",
       " 'environmental issue',\n",
       " 'Academia',\n",
       " 'Attacks',\n",
       " 'Feminism',\n",
       " 'Sports',\n",
       " 'Internet-Cyberspace',\n",
       " 'Science',\n",
       " 'Sixltr',\n",
       " 'conj',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'negemo',\n",
       " 'social',\n",
       " 'certain',\n",
       " 'percept',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'time',\n",
       " 'Arts, Culture, Entertainment, Sports',\n",
       " 'Business and Industrial',\n",
       " 'Law, Government and Politics',\n",
       " 'religion & social epistemology']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_pickle('FakeNewsMaster-dup.pkl')\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17934 entries, 0 to 17933\n",
      "Data columns (total 28 columns):\n",
      "TF                                      17934 non-null int64\n",
      "Bigram TF                               17934 non-null int64\n",
      "No. of Stop_words                       17934 non-null float64\n",
      "Out of Context                          17934 non-null int64\n",
      "Arts, Culture, Entertainment, Sports    17934 non-null float64\n",
      "Conspiracy                              17934 non-null float64\n",
      "Business and Industrial                 17934 non-null float64\n",
      "economy, business and finance           17934 non-null float64\n",
      "Religion and belief                     17934 non-null float64\n",
      "Law, Government and Politics            17934 non-null float64\n",
      "Education                               17934 non-null float64\n",
      "Technology and Computing                17934 non-null float64\n",
      "Science                                 17934 non-null float64\n",
      "Sixltr                                  17934 non-null float64\n",
      "conj                                    17934 non-null float64\n",
      "interrog                                17934 non-null float64\n",
      "number                                  17934 non-null float64\n",
      "negemo                                  17934 non-null float64\n",
      "social                                  17934 non-null float64\n",
      "certain                                 17934 non-null float64\n",
      "percept                                 17934 non-null float64\n",
      "focuspast                               17934 non-null float64\n",
      "focuspresent                            17934 non-null float64\n",
      "time                                    17934 non-null float64\n",
      "PERSON                                  17934 non-null float64\n",
      "TIME                                    17934 non-null float64\n",
      "ORG                                     17934 non-null float64\n",
      "GPE                                     17934 non-null float64\n",
      "dtypes: float64(25), int64(3)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13768\n",
       "0     4166\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=features.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.40000000e+01, 1.70000000e+01, 3.78116343e-01, 9.14000000e+02,\n",
       "        4.50800000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.71200000e-01, 0.00000000e+00, 4.50800000e-01,\n",
       "        0.00000000e+00, 1.94900000e+01, 6.39000000e+00, 9.60000000e-01,\n",
       "        1.76000000e+00, 3.20000000e-01, 1.66100000e+01, 4.80000000e-01,\n",
       "        3.67000000e+00, 6.55000000e+00, 5.59000000e+00, 5.75000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dependant variable y\n",
    "y= df.loc[:,['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17934"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14347"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adith\\anaconda3\\envs\\ANZ\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(features.columns) \n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = input_dim ,kernel_initializer='he_uniform', bias_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform', bias_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='he_uniform', bias_initializer='zeros', activation = 'relu'))\n",
    "# model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adith\\anaconda3\\envs\\ANZ\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "14347/14347 [==============================] - 0s 34us/step - loss: 0.5831 - accuracy: 0.7164\n",
      "Epoch 2/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.5088 - accuracy: 0.7673\n",
      "Epoch 3/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.4839 - accuracy: 0.7717\n",
      "Epoch 4/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.4597 - accuracy: 0.7787\n",
      "Epoch 5/60\n",
      "14347/14347 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.79 - 0s 28us/step - loss: 0.4332 - accuracy: 0.7919\n",
      "Epoch 6/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.4025 - accuracy: 0.8121\n",
      "Epoch 7/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.3689 - accuracy: 0.8353\n",
      "Epoch 8/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.3349 - accuracy: 0.8593\n",
      "Epoch 9/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.3021 - accuracy: 0.8801\n",
      "Epoch 10/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.2729 - accuracy: 0.8948\n",
      "Epoch 11/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.2483 - accuracy: 0.9078\n",
      "Epoch 12/60\n",
      "14347/14347 [==============================] - 0s 27us/step - loss: 0.2280 - accuracy: 0.9163\n",
      "Epoch 13/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.2107 - accuracy: 0.9230\n",
      "Epoch 14/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.1970 - accuracy: 0.9290\n",
      "Epoch 15/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1855 - accuracy: 0.9341\n",
      "Epoch 16/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.1759 - accuracy: 0.9378\n",
      "Epoch 17/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.1676 - accuracy: 0.9420\n",
      "Epoch 18/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1609 - accuracy: 0.9430\n",
      "Epoch 19/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.1546 - accuracy: 0.9456\n",
      "Epoch 20/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1495 - accuracy: 0.9465\n",
      "Epoch 21/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.1450 - accuracy: 0.9488\n",
      "Epoch 22/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.1408 - accuracy: 0.9513\n",
      "Epoch 23/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1368 - accuracy: 0.9530\n",
      "Epoch 24/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.1332 - accuracy: 0.9532\n",
      "Epoch 25/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1300 - accuracy: 0.9546\n",
      "Epoch 26/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1268 - accuracy: 0.9550\n",
      "Epoch 27/60\n",
      "14347/14347 [==============================] - 0s 27us/step - loss: 0.1242 - accuracy: 0.9562\n",
      "Epoch 28/60\n",
      "14347/14347 [==============================] - 0s 27us/step - loss: 0.1217 - accuracy: 0.9568\n",
      "Epoch 29/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1195 - accuracy: 0.9578\n",
      "Epoch 30/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.1171 - accuracy: 0.9578\n",
      "Epoch 31/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.1150 - accuracy: 0.9596\n",
      "Epoch 32/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1128 - accuracy: 0.9614\n",
      "Epoch 33/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1110 - accuracy: 0.9617\n",
      "Epoch 34/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.1094 - accuracy: 0.9622\n",
      "Epoch 35/60\n",
      "14347/14347 [==============================] - 0s 27us/step - loss: 0.1074 - accuracy: 0.9625\n",
      "Epoch 36/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1060 - accuracy: 0.9619 0s - loss: 0.1060 - accuracy: 0.96\n",
      "Epoch 37/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.1045 - accuracy: 0.9629\n",
      "Epoch 38/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1031 - accuracy: 0.9619\n",
      "Epoch 39/60\n",
      "14347/14347 [==============================] - 0s 26us/step - loss: 0.1015 - accuracy: 0.9637\n",
      "Epoch 40/60\n",
      "14347/14347 [==============================] - 0s 29us/step - loss: 0.1003 - accuracy: 0.9645\n",
      "Epoch 41/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.0990 - accuracy: 0.9639\n",
      "Epoch 42/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.0981 - accuracy: 0.9640\n",
      "Epoch 43/60\n",
      "14347/14347 [==============================] - 0s 32us/step - loss: 0.0967 - accuracy: 0.9658\n",
      "Epoch 44/60\n",
      "14347/14347 [==============================] - 0s 28us/step - loss: 0.0955 - accuracy: 0.9658\n",
      "Epoch 45/60\n",
      "14347/14347 [==============================] - 0s 30us/step - loss: 0.0945 - accuracy: 0.9656\n",
      "Epoch 46/60\n",
      "14347/14347 [==============================] - 0s 27us/step - loss: 0.0936 - accuracy: 0.9663\n",
      "Epoch 47/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0924 - accuracy: 0.9674\n",
      "Epoch 48/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0917 - accuracy: 0.9682\n",
      "Epoch 49/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0905 - accuracy: 0.9667\n",
      "Epoch 50/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0898 - accuracy: 0.9670\n",
      "Epoch 51/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0887 - accuracy: 0.9676\n",
      "Epoch 52/60\n",
      "14347/14347 [==============================] - 0s 23us/step - loss: 0.0879 - accuracy: 0.9676\n",
      "Epoch 53/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0871 - accuracy: 0.9682\n",
      "Epoch 54/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0864 - accuracy: 0.9691\n",
      "Epoch 55/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0854 - accuracy: 0.9685\n",
      "Epoch 56/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0848 - accuracy: 0.9690\n",
      "Epoch 57/60\n",
      "14347/14347 [==============================] - 0s 24us/step - loss: 0.0838 - accuracy: 0.9691\n",
      "Epoch 58/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0834 - accuracy: 0.9699\n",
      "Epoch 59/60\n",
      "14347/14347 [==============================] - 0s 25us/step - loss: 0.0822 - accuracy: 0.9704\n",
      "Epoch 60/60\n",
      "14347/14347 [==============================] - 0s 23us/step - loss: 0.0814 - accuracy: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e942d7a9b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs = 60, batch_size = 32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 0s 14us/step\n",
      "\n",
      "accuracy: 95.37%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[ 739   79]\n",
      " [  87 2682]]\n"
     ]
    }
   ],
   "source": [
    "y_pred= model.predict(test_x)\n",
    "\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "\n",
    "print(\"Confusion matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANZ",
   "language": "python",
   "name": "anz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
